<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Blog</title>
    <link>https://contracourse.github.io/blogpage/</link>
    <description>Recent content on Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 09 Apr 2023 18:38:43 +0200</lastBuildDate><atom:link href="https://contracourse.github.io/blogpage/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Banking</title>
      <link>https://contracourse.github.io/blogpage/docs/banking/</link>
      <pubDate>Sun, 09 Apr 2023 18:38:43 +0200</pubDate>
      
      <guid>https://contracourse.github.io/blogpage/docs/banking/</guid>
      <description>80% of bank in lending in the US und the UK are mortgages, because the general prosperity is raising therefore pushing up property prices in general.
The key to understand the financial sector&amp;rsquo;s strategy is that its activities and revenue do not constitute a part of real economic growth, but a subtrahend paid out of the economic surplus.
Most of the wealth for families has stemmed from the debt-leveraged price of their homes.</description>
    </item>
    
    <item>
      <title>Bayesian Additive Regression Trees in R</title>
      <link>https://contracourse.github.io/blogpage/docs/bart/</link>
      <pubDate>Sun, 09 Apr 2023 18:29:50 +0200</pubDate>
      
      <guid>https://contracourse.github.io/blogpage/docs/bart/</guid>
      <description>Introduction Gradient boosting methods are commonly used in the Machine Learning field. It&amp;rsquo;s a rather straight forward process as it utilized &amp;ldquo;tree boosting&amp;rdquo; optimization methods by combining random forest algorithms with a learning rate. Gradient boosting algorithms are seeking to minimize an objective function.
$$E[y-\tilde{y}]=\underbrace{\sum_{i=1}^I \text{loss}(y_i,\tilde{y}i)}{\text{error term}} \quad + \underbrace{\sum_{j=1}^J\lambda(T_j)}_{\text{regularization term}}$$
$$E[y-\tilde{y}] = \sum_{i=1}^I \text{loss}(y_i,\tilde{y}i)\sum{j=1}^J\lambda(T_j)$$
$$\underbrace{a+b+c}_{\text{note}}$$
This is an inline equation: $$V_{sphere} = \frac{4}{3}\pi r^3$$,
Most common machine learning algorithms are using a similar basic objective function which is based on a frequentist approach towards statistics.</description>
    </item>
    
    <item>
      <title>Test</title>
      <link>https://contracourse.github.io/blogpage/docs/test/</link>
      <pubDate>Sun, 09 Apr 2023 17:46:13 +0200</pubDate>
      
      <guid>https://contracourse.github.io/blogpage/docs/test/</guid>
      <description>This is a testpage This is a test</description>
    </item>
    
  </channel>
</rss>
